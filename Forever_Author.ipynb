{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forever_Author.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Loading In Our Packages and Data\n",
        "In this project, we will use the keras package to generate a sequential R.N.N. using a Long Short Term Memory model and RMS Prop optimizer"
      ],
      "metadata": {
        "id": "hfuGXNK8JSup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NKYTvreyK74c"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random \n",
        "import sys\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in our text file from the **Gutenberg eBook online library**, an open sourced collection of books collected from across the world. We will be using Sherlock Holmes due to it's\n",
        "\n",
        "- Complex sentence structure \n",
        "- Popularity and familiarity\n",
        "- Mix of classical and modern english vernacular\n",
        "- Unique writing style. \n",
        "\n",
        "As such, it should prove interesting  to replicate."
      ],
      "metadata": {
        "id": "iZYcqsXEJ1_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O sherlock_holmes.txt http://www.gutenberg.org/files/1661/1661-0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyLU6ue9LSp0",
        "outputId": "fc5d8774-8524-44af-c6f9-147491bc3a58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-17 08:35:54--  http://www.gutenberg.org/files/1661/1661-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.gutenberg.org/files/1661/1661-0.txt [following]\n",
            "--2022-03-17 08:35:55--  https://www.gutenberg.org/files/1661/1661-0.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607430 (593K) [text/plain]\n",
            "Saving to: ‘sherlock_holmes.txt’\n",
            "\n",
            "sherlock_holmes.txt 100%[===================>] 593.19K  1.17MB/s    in 0.5s    \n",
            "\n",
            "2022-03-17 08:35:55 (1.17 MB/s) - ‘sherlock_holmes.txt’ saved [607430/607430]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will perform minimal analysis, such as length of the text read in as well as a sample of the text. "
      ],
      "metadata": {
        "id": "wrsI9v01LFsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('sherlock_holmes.txt', 'r').read().lower()\n",
        "print('text length', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU0dycCELwhH",
        "outputId": "f8a58e0f-aa43-4465-d698-41ee64976948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text length 581533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltXgSbUaL0WU",
        "outputId": "7e5e8f69-ea59-4860-ed3d-ee3920b4c8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿the project gutenberg ebook of the adventures of sherlock holmes, by arthur conan doyle\n",
            "\n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the project gutenberg license included with this ebook or online at\n",
            "www.gutenberg.org. if you are not located in the united states, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this ebook.\n",
            "\n",
            "title: the adventures of sherlock holmes\n",
            "\n",
            "author: arthur conan doyle\n",
            "\n",
            "release date: november 29, 2002 [ebook #1661]\n",
            "[most recently updated: may 20, 2019]\n",
            "\n",
            "language: english\n",
            "\n",
            "character set encoding: utf-8\n",
            "\n",
            "produced by: an anonymous project gutenberg volunteer and jose menendez\n",
            "\n",
            "*** start of the project gutenberg ebook the adventures of sherlock holmes ***\n",
            "\n",
            "cover\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the adventures of sherlock holmes\n",
            "\n",
            "by arthur conan doyle\n",
            "\n",
            "\n",
            "contents\n",
            "\n",
            "   i.     a scandal in bohemi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First Step**: \n",
        "Changing Mapping of Characters to Integers"
      ],
      "metadata": {
        "id": "QQ1mBRxQecSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ', len(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiafgWssNUAc",
        "outputId": "848b4346-10b2-4cb5-8e77-509fff20e6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars:  72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "NV6sK6tzNejL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second Step**: Splitting Sequence of Integers into Fragments\n",
        "\n",
        "In the below step, we split our sequences of characters into 3 arrays of 40 character sequences at each index for the whole book. "
      ],
      "metadata": {
        "id": "2fGH7gzQeen0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nypMUqSkNfmO",
        "outputId": "72d9dc55-a9eb-4438-d6cd-dd7920ae9c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 193831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4zEPjD-Nix1",
        "outputId": "f6578bb6-a7e6-4f17-b724-85c876b1665b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffthe project gutenberg ebook of the adve', 'e project gutenberg ebook of the adventu', 'roject gutenberg ebook of the adventures']\n",
            "['n', 'r', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Third Step**: Changing our array of character sequences into a boolean array for the computer to understand "
      ],
      "metadata": {
        "id": "SOAQfaA2M_Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "Kha_iXCvNmBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:3])\n",
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WdIhsr_NvzO",
        "outputId": "d6e9066c-79eb-4cca-d484-0a4826b177d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False  True False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourth Step**: Building Our R.N.N. Model"
      ],
      "metadata": {
        "id": "YTCIpAwWei6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "MYzDjkZNNy71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "3NDV_LoyN2cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fifth Step**: Helper Functions for improving model as it trains"
      ],
      "metadata": {
        "id": "Uget9gNAekrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "AW1FkDQnN-IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "metadata": {
        "id": "LqkegbhOOA5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sixth Step**: Creating Callback functions to save our model each epoch and and reduce learning rate as it flattens"
      ],
      "metadata": {
        "id": "hHO6cvu6enBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ],
      "metadata": {
        "id": "7-I29JEEOHlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)"
      ],
      "metadata": {
        "id": "KkLTjctbOKSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "2KBOfFAYONNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seventh Step**: Training Our Model"
      ],
      "metadata": {
        "id": "AMQ3UUknepnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=10, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHv9VcNjOO4l",
        "outputId": "eee21c48-e0c5-4796-e8b7-8d7a8890bbce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3415\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" project\n",
            "gutenberg-tm collection. despit\"\n",
            " project\n",
            "gutenberg-tm collection. despitit and was a distance which is a completion and what i have a complete and which i have a completion of the string and a small mince and a completement and which he was a man who have the morning of the string and down and the man who has done the promer state the lamp and than the streets of the fire of the street. i have a complete and that i have a confinere of the string and was a fire of the \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" project\n",
            "gutenberg-tm collection. despit\"\n",
            " project\n",
            "gutenberg-tm collection. despitit\n",
            "of our one of a londof of the property.”\n",
            "\n",
            "“but the promothy seemed in his each of the stumusion the complemess of my rooms of some\n",
            "london of the same of his wife at the man who has frenk upon your conventrant words and than i have a coloured from the last and was a man morning in the lock, and i had been the considerable to streetly the secret and was the streets of some secret to the london in\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" project\n",
            "gutenberg-tm collection. despit\"\n",
            " project\n",
            "gutenberg-tm collection. despition to his face, andithen tore down sires. a long left, “silen we mave been heard ah clother. he had desspieds. at alluter by his hand-in the hops of lay su, there\n",
            "who are the latter of a lorders cribles.”\n",
            "\n",
            "“god, and his\n",
            "end. \n",
            "“walked pilk, fact which\n",
            "must palded up a funngess than a certain. he had his sanualifed with be did. you lay mable fdoject attriat?” i thorived\n",
            "holmes little clueged lord w\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" project\n",
            "gutenberg-tm collection. despit\"\n",
            " project\n",
            "gutenberg-tm collection. despiticy are ionple, for the wishe, and visitor\n",
            "believen ienled, and, i 1ltro you the connciorims acrostry singled.”\n",
            "\n",
            "hosmer“isplotty was it’s while ne.” and hreef\n",
            "wased aw said my from at all,\n",
            "iil doj‘et lips butcabed\n",
            "for never pyile, and i think that it was quity know a groam. neyes. proacheesiction air diston.”\n",
            "\n",
            "i when it is stiftame, and it is a grains etself he the\n",
            "amering hhar. she drove occurrie\n",
            "\n",
            "Epoch 1: loss improved from 1.36289 to 1.34148, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 199s 131ms/step - loss: 1.3415 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3349\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"r and out at the other. i\n",
            "think that was\"\n",
            "r and out at the other. i\n",
            "think that was the london and the man was a country to the books. the corner of the facts was the low of the corner of the beddite to the beddary to the profess. it is one of the beddard with the firmustion in the corner of the corner of the stript and the facts were at the track of the tracks were started to the tracks of the man was all the trained of the probably to the low to the barm of the track of the co\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"r and out at the other. i\n",
            "think that was\"\n",
            "r and out at the other. i\n",
            "think that was always weeks at the bottoch heard at the bank with the night round the complice of tall with the front of the front strange to tell you and controan of the projecting for his corridgel back of the traces in the passerd. i shall be better to street only to the treach and firmy of the office to the beartias that i have a good by the fires face and to see the street of a few minutes.”\n",
            "\n",
            "“i should be \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"r and out at the other. i\n",
            "think that was\"\n",
            "r and out at the other. i\n",
            "think that was to call bake for hone a castes-howing  fur dist\n",
            "it at it!” he arefyevest with his man struck the offord ha.f?”\n",
            "\n",
            "“hu’ll you struck house and miry. “i gaber you begran matter to me.”\n",
            "\n",
            "“if not threely bepovisuam-station of the tarms.\n",
            "but evermed brother. then he seems to see the laodes.\n",
            "\n",
            "“but it is weld toshise, because about about everytenixed,\n",
            "in thrs.\n",
            "\n",
            "“hoonipyy do you vicle i bake a jabes was ha\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"r and out at the other. i\n",
            "think that was\"\n",
            "r and out at the other. i\n",
            "think that was thought varihatse wonden scate stranked out swinging-sivcing, with a\n",
            "greacttence form sleeve and with an a upon the rron among you streturd holmes\n",
            "drop covit afulmomadycee. that we gone\n",
            "to her road?” he the matter off to the sbauinter cromied a\n",
            "of girloqusoulart.\n",
            "\n",
            "“for an examiny.”\n",
            "\n",
            "“these the usualle.’ wall.\n",
            "remordas—the pire send could be the groundal wit teems, an-hleed, you have given. in usi\n",
            "\n",
            "Epoch 2: loss improved from 1.34148 to 1.33500, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 198s 131ms/step - loss: 1.3350 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3291\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"o cares for me, and he, poor fellow, can\"\n",
            "o cares for me, and he, poor fellow, can there was a little part to the staid to the coroner. i should be a compliast of the coroner, and there was a case in the more to the first to the first to the case of the stairs of the copy to the first to the colonel which i must might the lady and the street and the first was the staid and the words i should throw that i have a compliast the staid with the colonel which i should come to the col\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"o cares for me, and he, poor fellow, can\"\n",
            "o cares for me, and he, poor fellow, can i think them the tramply and the preceriance, and no come, and then some copless boot the staid case and then i must have a chine them throok of his first, i think that i should do him at the windowly the station of such an ordered to say that the first was the first of the brown that the staid of a starter such a copyritgen to my startes in his companion of the police. there is a house that this\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"o cares for me, and he, poor fellow, can\"\n",
            "o cares for me, and he, poor fellow, caned up when he wisht is a look of though, thank you appears ded my\n",
            "moment\n",
            "worr\n",
            "which i shall not be\n",
            "broum. my finger was thoughtwere suching, and husfess cheet icpirest are eyelages that soming a\n",
            "was of my .ond our way were me. or may to, and that see all that i shall under i pay be passed. thenk then? it is a light man that i must\n",
            "me, throw which has find that i untulte in lijess to me kway the\n",
            "wo\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"o cares for me, and he, poor fellow, can\"\n",
            "o cares for me, and he, poor fellow, cang for silence. il, no blex expre”ci sable.”\n",
            "\n",
            "oh, syarwout your desclegely\n",
            "of disturdd\n",
            "to fen them.”\n",
            "\n",
            "“i shoull on veryclves good restion to hea deading\n",
            "hes adooced\n",
            "fall. we\n",
            "feelimon,\n",
            "and failly there to polead a ghrict b clubsul which i was hes now a grey dong arcrouny and that\n",
            "highl?”\n",
            "\n",
            "uh-cladydccaidly had turned\n",
            "them therehurd this left getter or age, price. ‘but i\n",
            "am all.”\n",
            "\n",
            "“then\n",
            "it stoop yet, \n",
            "\n",
            "Epoch 3: loss improved from 1.33500 to 1.32912, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 199s 131ms/step - loss: 1.3291 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3206\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ngs have not been so\n",
            "plentiful with me a\"\n",
            "ngs have not been so\n",
            "plentiful with me a feeling of the country of the sound of the matter to a few years of the countest of the other of the matter and the sound with the corridon of the work of the country of the being in the country and the matter which i have been a few minutes which i have been more than the sound of the matter of the single with the work of the matter of the matter of the offices in the house of the matter of the \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ngs have not been so\n",
            "plentiful with me a\"\n",
            "ngs have not been so\n",
            "plentiful with me a little the sight indeed in a deady to the between the rooms, which i should see that when i have been works in a very mission as on the sound a propositors and was the gentleman work upon the matter and that he had been finger to a humbing with me to have been things than the matter was married to you. i should be too from the matter. now, when i have not do not do not did not see how i have not \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ngs have not been so\n",
            "plentiful with me a\"\n",
            "ngs have not been so\n",
            "plentiful with me all revest that, the\n",
            "garding in the wealice disson, dropped my eather signs havinit. shelmer frispatis as all but hear, for i have\n",
            "instage, risingll betoncmed there\n",
            "to\n",
            "succed to his boych!”\n",
            "\n",
            "“his give inprepay deef an abott with her.”\n",
            "\n",
            "“they was in a naffollunage, pevhop,” said holmes. “i start a be tin a bare of his vigure and to instails in his head my face,\n",
            "\n",
            "“and a would see may confinary imredi\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ngs have not been so\n",
            "plentiful with me a\"\n",
            "ngs have not been so\n",
            "plentiful with me a most in theaw?”\n",
            "\n",
            "“yes, wrifinat flessed with a tending of the hindriffies of the head as filiser and with m of time of 18hacraiply meanulwern out of with flools from like\n",
            "ofe. but repening his bis we begincial bickting of\n",
            "one soxury litell under.\n",
            "thinmly would make the way up his hin inwotso down upon the bame of sicked ve?”\n",
            "\n",
            "“no, welherwer.”\n",
            "\n",
            "“here was englandpench ‘friends, i try mander. i have\n",
            "\n",
            "Epoch 4: loss improved from 1.32912 to 1.32054, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 200s 132ms/step - loss: 1.3205 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3155\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"e, and they like\n",
            "to do their own secreti\"\n",
            "e, and they like\n",
            "to do their own secretic of the coronet, and the man who is no more than the states which she strange the continue to me that i should see the station. she saw a word of the ground the continue and that she was a lower and was the room, and the continue at the state which i had a considerable which i have a complete which i have been man and continued the continue to the continue. the staid was the continue for the comp\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e, and they like\n",
            "to do their own secreti\"\n",
            "e, and they like\n",
            "to do their own secreting of the momentand to the man and was the rooms which i had been provition, and these manners the greatence to me. i am not enough to the starthely and down at the money. there were some colour of the\n",
            "station, which were forward a craps and saw a crime me the fact of the danger, then it was at the propest the considerable as what had been any property,’ said i was in the sticks bears of the\n",
            "diffi\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e, and they like\n",
            "to do their own secreti\"\n",
            "e, and they like\n",
            "to do their own secretions\n",
            "with yards as and\n",
            "deecy laid able to than the left the name,’ , druve, comally price someone in his apersman about when me the possible to my two and coinerd, mr.\n",
            "holmes!” he clattle they might be difficills in anyone you to get do ball shook you which he was actuel as that you are\n",
            "ringlingss by some jabe?’s and with the deepen. it is will to putten hawd, that missing had been feeling to what \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"e, and they like\n",
            "to do their own secreti\"\n",
            "e, and they like\n",
            "to do their own secretiem’s minute was away face in his\n",
            "i’story, see that her hyctair. what you?”\n",
            "\n",
            "“goodd, to dra.”\n",
            "\n",
            "“never.\n",
            "shown\n",
            "out his housek as not peaps a site him.”\n",
            "\n",
            "“you found\n",
            "the low.\n",
            "“now, i have beeny . bow that saw what i\n",
            "say passads\n",
            "‘on the methh name as sight leave and ground seen which\n",
            "ienashed it is nollx.”\n",
            "\n",
            "i turned over his, and there.”\n",
            "\n",
            "“you are cutrive himled, yourd?’ asked \n",
            "withinh, thinkkfied issha\n",
            "\n",
            "Epoch 5: loss improved from 1.32054 to 1.31556, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 201s 133ms/step - loss: 1.3156 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3107\n",
            "----- Generating text after Epoch: 5\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ed about\n",
            "looking for matches and mutteri\"\n",
            "ed about\n",
            "looking for matches and muttering the leaves in the since and street and the first was the leaves and the last was the silence of the coronet, and the coronet of the coronet of the country and strange holmes, and the leaves which he had been an and the lady and work the leaves of the coronet, and i shall be at the leave of the sight of the door of the coronet, and the country is a coronet that i have the leave the coronet of th\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ed about\n",
            "looking for matches and mutteri\"\n",
            "ed about\n",
            "looking for matches and muttering me that a de’s blet use the first grey for a small came of a few amiage which he had done his cry and importanting in shoulders, and\n",
            "the present in the silence of his head and clear upon the precerse\n",
            "with a\n",
            "sitting the coronet, and i am as i as\n",
            "a copyly stone and implical profession which she was long for well-hatherliched with a could have been sheed in the coronet, of a slippers, enough it wi\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ed about\n",
            "looking for matches and mutteri\"\n",
            "ed about\n",
            "looking for matches and mutteris. thrilater is a few the\n",
            "pergeseld-can wit rat, as i smokingen to having missed been his wife is burphe methying quite either.”\n",
            "\n",
            "“you seem yourseepen in the smoked lown pullessis and went, but the by him we may i have alloed the oler-an usboring of and leaving the finauls\n",
            "is it into the\n",
            "despeciar\n",
            "of with the mray waid when we heartwar ised by usaid, as i ready from my ricking the agving the nook.\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ed about\n",
            "looking for matches and mutteri\"\n",
            "ed about\n",
            "looking for matches and mutteriat\n",
            "and itjoctions,” remp, a\n",
            "wire-week refer me i\n",
            "whoprone. shall say re; but altholow from the nastant half, and, m sli‘ing agrouin.”\n",
            "\n",
            "“ho yous wonfided backutured\n",
            "wogre\n",
            "seeard glanced. but, judged,” he\n",
            "end the iods as he was time inwith it, and the\n",
            "iney, aw seen scriense sty, you been to who have yoursead of at least it faced site hi sho havediluse, disdeviem?’\n",
            "\n",
            "“i must have alidought issmeched o\n",
            "\n",
            "Epoch 6: loss improved from 1.31556 to 1.31069, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 200s 132ms/step - loss: 1.3107 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3049\n",
            "----- Generating text after Epoch: 6\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \", raising his golden pince-nez to his\n",
            "ey\"\n",
            ", raising his golden pince-nez to his\n",
            "eyes of the prince and the coroner and which i shall see that the last was the coroner was a little the matter with a colour of the coroner of the coroner, when i cannot see the coroner which were the coroner, and the most commonces of the coroner which i have a companion and the coroner with the strange windows and a small me with a coroner. then i have a companion and a caller which i have a compa\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \", raising his golden pince-nez to his\n",
            "ey\"\n",
            ", raising his golden pince-nez to his\n",
            "eyes of the bed of the turn of in the matter that he stood the collects of the coroner to the street friends at the morning. i can see that he threw you received to the back, and there was a letter the reasonation of the cold the matter that i have not another and my wife at the came of made of the other indict of marked of the dead hurry into the most be an opened with a same memerely of the work a\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \", raising his golden pince-nez to his\n",
            "ey\"\n",
            ", raising his golden pince-nez to his\n",
            "eyes,\n",
            "right was no thing, and\n",
            "very good essents, but on\n",
            "it. was an affairates\n",
            "would have within the\n",
            "freshan eccroan room. on\n",
            "my society of your friet avoyef succeed scateinoather of the other of the place.”\n",
            "\n",
            "“obvicemsear he has not inform incluses then’\n",
            "naffortunally.’ the doin.”\n",
            "\n",
            "“‘do you your nicel, and kester means which got out of found horner to his mout    refecled under this written privial a\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \", raising his golden pince-nez to his\n",
            "ey\"\n",
            ", raising his golden pince-nez to his\n",
            "eyes,” said my cussangerly,” cut you before see merselbert him, a came.”\n",
            "\n",
            "\n",
            "bigsarive they brinking\n",
            "last struggle upcastom prayerver to triceling a blaode.”\n",
            "\n",
            "“eyesher would vilules.” \n",
            "rewer for the knees when\n",
            "are guessed downition, so mand\n",
            "i talkt to be rangly an of tenring. now a cermain yater our opinging, and town youd the sulk in you callimen iosteds by then\n",
            "lust ounsly\n",
            "on eedn perfectly cast-not\n",
            "\n",
            "Epoch 7: loss improved from 1.31069 to 1.30489, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 200s 132ms/step - loss: 1.3049 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.3017\n",
            "----- Generating text after Epoch: 7\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" to understand a little\n",
            "more clearly wha\"\n",
            " to understand a little\n",
            "more clearly what i had been a complete in the compliate of the counter, and that i have been my states of the companion, and the states was the state of the state of the considerable as in the room of the compention of the matter and the states and saw that i had been compliated to the counter which i have been a little the state of the door of the states of the counter of the state of the company state in the c\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" to understand a little\n",
            "more clearly wha\"\n",
            " to understand a little\n",
            "more clearly what i had been the strange keeper, but the considerally stood had gone to the door. i know that he would see your mostion of the counting of the confinery. the terribly he was but last being her in the force of\n",
            "his clear\n",
            "and had been the little way with a copper beeches and return the distributed the could have been there was some precious as that when i do not know that he would be an opening the w\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" to understand a little\n",
            "more clearly wha\"\n",
            " to understand a little\n",
            "more clearly what times took to the gentleman yar clather as she might raised into his frient of rederits of the box. then reces to a certain speats and , with the first sat. but when he was objurap,” ord and spent, and much bed\n",
            "most coinlersitguinars than what o’cl\n",
            "sheets of us? when when i forg fath\n",
            "as been your\n",
            "wastervering upon stead in, still how lenting that\n",
            "you frocled in our man who seep to weral time wit\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" to understand a little\n",
            "more clearly wha\"\n",
            " to understand a little\n",
            "more clearly whatever answered a commonapalice nostal mikel out holmes, and if that if i live to the centr and landed\n",
            "which, from\n",
            "oneci to thectic side. dut none let, a little excidence!” said  peily upon indipomplunict, withear hese\n",
            "here whine worrs?”\n",
            "\n",
            "“yer, no-b.\n",
            "\n",
            "“non\n",
            "the thrup coundryd obboindcy sciess and dreadn\n",
            "mary upon it akent the\n",
            "houned which she\n",
            "have no seattle never little\n",
            "werdbest, but to all that wi\n",
            "\n",
            "Epoch 8: loss improved from 1.30489 to 1.30163, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 200s 132ms/step - loss: 1.3016 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.2964\n",
            "----- Generating text after Epoch: 8\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" bed. the lash, however, was curled upon\"\n",
            " bed. the lash, however, was curled upon the morning, and the station was a companion, and the man who will be a station and that the coroner\n",
            "was the matter of the matter and to the sight of the state of the matter and was the some of the matter and that he has a small close, and the station was a small with a companion, and the matter had stone a small close which was a small for of the coroner was a small curly which i have a companio\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" bed. the lash, however, was curled upon\"\n",
            " bed. the lash, however, was curled upon his\n",
            "profesty and complice and for the sign of the most inceared in the corness of the house of the place which was a frighted in the man who have a passing in the trained at the houses, and i have already was over head his continued with sherlock holmes. “the fire, miss, and the man who will he did not promise when i was a constant, and in his case and what are he was in the thing the constant, a\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" bed. the lash, however, was curled upon\"\n",
            " bed. the lash, however, was curled upon\n",
            "the bare little night. “your unside ,ogasgehs, met clock a just read the between a wrying,” i and the fact of rediraled. “i hushed by word to me to me to a mair. the fowcreen is fand oolfants, but you say to readcoutiess.”\n",
            "\n",
            "“the coundat was haald all rough.n?’\n",
            "\n",
            "“‘i shone it the of and word upon the end\n",
            "musture in the floreth of good-costation. he is over to alout  conty-and of friend?”\n",
            "\n",
            "“now keep\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" bed. the lash, however, was curled upon\"\n",
            " bed. the lash, however, was curled upon on!\n",
            "the suddenlall-ctrear you\n",
            "as. you pey beat, and\n",
            "cerfled,\n",
            "opened your such forlecf hurrs,\n",
            "so were bo bobbed towards, and waiting out hair the machimp turn it. so empacts i years discust, and from i took. come,\n",
            "at the prebiling of astinm into my difficultual, and so my eyel, two impored eamenthy. in your infouniat sleemed me cut a longer’s,” said son,\n",
            "i have been tixing, and agairs to e-viounon\n",
            "\n",
            "Epoch 9: loss improved from 1.30163 to 1.29640, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 202s 134ms/step - loss: 1.2964 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "1514/1515 [============================>.] - ETA: 0s - loss: 1.2936\n",
            "----- Generating text after Epoch: 9\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"to go into the empty wing,’ i answered. \"\n",
            "to go into the empty wing,’ i answered. “i shall send the sector of the singular and the last was all the stairs of the bank of the stair.”\n",
            "\n",
            "“i shall send the strange to the stair. i shall send the last in the first of the man which i was a little and the last was all the conclusion of the contince and the man which was all as she had all strange and the state of the startes and the contince to me to see the state of the country. i shal\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"to go into the empty wing,’ i answered. \"\n",
            "to go into the empty wing,’ i answered. “what did you can be something of the advertisement in the loss of the man of the start fecture as i shall be something a news in the money without sole as mank which he remarked, i was which she was a small in\n",
            "ever which he must be all and the sound of the loss of the stathy poor was the\n",
            "man and son and the sight of the sight of the stairs of a realice, for i should sold me to come and the compla\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"to go into the empty wing,’ i answered. \"\n",
            "to go into the empty wing,’ i answered. “hus? ho took land my fathorabil, i faile\n",
            "to\n",
            "goven suficions.”\n",
            "\n",
            "“there was nork\n",
            "in lighted of any forthial\n",
            "three forcefing. “i canmnight for day that i can do then would have, now.”\n",
            "\n",
            "“loudoned abous contlouring it await, not-ro, and i rethred now,\n",
            "but he was this\n",
            "much profession is\n",
            "fron\n",
            "and informence to doctor on plaup of sodspiess which arewe is nicels\n",
            "you for lead until to him, and i understven\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"to go into the empty wing,’ i answered. \"\n",
            "to go into the empty wing,’ i answered. “i hale you known good.\n",
            "but meford without businss, toicply proticult, mr.”\n",
            "\n",
            "“where was a very permin, grey thair tale.’\n",
            "\n",
            "“‘gatuess enom; costreaty. where\n",
            "causing down upstairs and take a week.\n",
            "truiardonddrule. as i taken do, withwaute. so door.”\n",
            "\n",
            "he dirlquarcy, and left it\n",
            "attacteee, he by\n",
            "said her\n",
            "hand\n",
            "six of shouldesyes.\n",
            "oh the offirest ramisgates unpleas being and think,\n",
            "intere teeply\n",
            "which sh\n",
            "\n",
            "Epoch 10: loss improved from 1.29640 to 1.29362, saving model to weights.hdf5\n",
            "1515/1515 [==============================] - 201s 133ms/step - loss: 1.2936 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f77997d6cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eighth Step**: Testing The Model to generate new texts"
      ],
      "metadata": {
        "id": "alJKEoDPetQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "    return generated"
      ],
      "metadata": {
        "id": "NLpgXur1T6OV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ninth Step**: Generating Texts of Various Length and Diversity"
      ],
      "metadata": {
        "id": "J-N-aIO6eupO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(500, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCdC-tE2T9El",
        "outputId": "7fb1f0fb-62fd-4920-f6c6-90316b7f8b50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for indian animals, which are sent\n",
            "over the man who is a man who was a small state of the last what i shall not be all there was a small state of the man which was a little particular which i was a man which was all the stairs of the country. i shall not be all there was a little bed to the part of the landram, and the last was not and the stairs and were all discovered to the countes of the man which i shall be a small started at the stairs of the complete in the man which i was a small time of the contination.\n",
            "\n",
            "“here is the man whic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(100, 0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJt6gWI_UMAU",
        "outputId": "ea246009-286d-4791-f29d-7d9fba972b80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ting, and the paper upon which it was\n",
            "writing.\n",
            "\n",
            "“he was\n",
            "mark, and the last was all the contination. the alter was a shadow of the party posi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(200, 0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_OuSaIqUR2V",
        "outputId": "47881b83-f87c-4450-d1c1-ef650956defc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he shoulder.\n",
            "\n",
            "“if you leave it to a court of the constanure of the state of the state of the constanure of the country. i shall be all there was a small state of the since that i shall not be all there was a small state of the state of the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(200, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J8bCw9zUbyS",
        "outputId": "32941dfe-2701-44d5-c8fe-e56f01e709e9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o his wife.’ there is half a column of pistol and as soctold of remember room,\n",
            "it told for the deather of last over the footmistmens to the sold of along to ever what there is make or the\n",
            "deepest of a large in the greet. there were beitany \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(1000, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvQr-1SUjSt",
        "outputId": "d8643415-8bed-4edd-b946-dbb9709fe8f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‘you see it is really\n",
            "confined to london, and the man was a little the man who was a little man shoulder. “i shall sent to me to be all the travelled and the stair, and there was a small state of the since that i shall be all there was a small man which was a small state of the contination. i shall be all there was a small state of the state of the contrarion. i shall be the man which i was a considerable bed to be a better in the stair and the singular and the last was all the last was all the man who is a little thinger and the stair and the continuar and some front of the man who is a little front of the man and the man who is all the last in the country. i had been at the first of the man which i should not think that i was a small state of the considerably and the man which i was letters to me. i should not think that i shall be all there in the first of the stair.”\n",
            "\n",
            "“i shall sell me to me to be the bow which i shall be been the last was all the stairs of the state of the contince to the man which were a small state of \n"
          ]
        }
      ]
    }
  ]
}